\subsection{Magnification and resolution}
Resolution is the ability for an imaging system to distinguish object detail, which often is expressed in line-pairs per millimeter (lp/mm) also known as frequency. % http://www.edmundoptics.com/technical-resources-center/optics/modulation-transfer-function 
A digital image has it's dimension in pixels and the resolution of digital images is the dimension of an image in pixels. The ratio between image and object size is known as the magnification for an optical system. To measure the resolution one can use different methods such as Rayleigh's criterion, modulation transfer function (MTF) and point spread function (PSF). 

% Detta är för avskrivet behöver omformuleras.
When using Rayleigh's criterion one find the distance between the images of two points sources as they are resolved. A better way to measure the resolution is to determine the MTF of the system. MTF is the ratio between input and output modulation/contrast, defined as \[ m = \frac{I_{max}-I_{min}}{I_{max}+I_{min}}. \] The contrast decreases when the spatial frequency of the lines increases. We estimate the resolution to be lines/mm where the MTF value is 0.5. % Reference labhandledningen
PSF describes the response from the imaging system with a point input. In an ideal image a point input is represented as a single pixel. PSF expresses system preferences in the spatial domain and MTF in the frequency domain. The two parameters are related by the Fourier transform, $ MTF = \mathcal{F}(PSF) $. The MTF curve is used to express the spatial frequency response of a system, and expresses normalized contrast as a function of spatial frequency. % http://medim.sth.kth.se/6l2872/F/F9.pdf

\subsection{Grey scale images, image format and image information}
Every pixel stored in the matrix as unsigned integer, which means that we can encounter some problems when performing mathematical operations, eg 150+150=255 or 10-33=0. For this reason we temporarily convert the matrix using the formula I=double(I)/255. 

When subtracting two images one subtracts each pixel in the first matrix with the corresponding pixel in the other matrix. %http://homepages.inf.ed.ac.uk/rbf/HIPR2/pixsub.htm
This means that if we subtract to identical images we will only get a black image since the intensity in each pixel will be 0, this also means that we could detect movement in the picture since some pixels will be displaced in the second image and the result will no longer be 0.

\subsection{Image enhancement}
Changing the intensity values of pixels is a common way to enhance images. Histogram equalization is often used when enhancing images. There are two requirements in order to use histogram equalization. The first is that the output image should use all available grey levels and the second is that the output image has approximately the same number of pixels of each grey level. Another method one can use to enhance an image is to use contrast stretching, in this method all output pixels are determined only by it's input pixel. When an image is of low contrast it is possible to use contrast stretching, but it is probably better to use histogram equalization, which means that the grey level values are equally distributed withing its total range.


%https://courses.cs.washington.edu/courses/cse576/book/ch5.pdf
\subsection{Colour images}


\subsection{IR - Imaging}